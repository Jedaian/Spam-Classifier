# -*- coding: utf-8 -*-
"""Spam_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PhEkeTjNyowWWZ0uwM3FYdcjdV6An4Kl
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
import re

dir = '/Users/jedai/Desktop/Data Science Projects/Spam Classifier/emails.csv'
df = pd.read_csv(dir)

df.head()

"""# EDA"""

df['spam'].value_counts()

"""Finding the total number of words for each email"""

def word_length(sentence):
  return len(re.findall(r'\w+', sentence))

df['word_number'] = df['text'].apply(word_length)

plt.figure(figsize = (12, 8))
sb.histplot(df['word_number'], bins=75)
plt.title('Total number of words in the Emails')
plt.show()

while(max(df['word_number']) >= 1500):
  idx = df['word_number'].idxmax()
  # print(idx)
  df.drop(idx, inplace= True)

plt.figure(figsize = (12, 8))
groups = df.groupby('spam')
label_map = {0: 'Not Spam', 1: 'Spam'}
for i, (name, group) in enumerate(groups):
    sb.histplot(group['word_number'], bins=50, alpha=0.5, label=str(label_map[name]))

plt.title('Word Count Distribution by Class')
plt.xlabel('Word Count')
plt.ylabel('Frequency')
plt.legend()
plt.show()

df['spam'].value_counts()

df_not_spam = df[df['spam'] == 0]
df_spam = df[df['spam'] == 1]

df_not_spam_downsampled = df_not_spam.sample(n=len(df_spam), random_state=1)

df_balanced = pd.concat([df_not_spam_downsampled, df_spam])

df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)

df_balanced['spam'].value_counts()

"""#Model and Training

Preprocessing
"""

from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
import nltk

nltk.download('punkt', quiet = True)
nltk.download('stopwords', quiet = True)

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    stemmer = PorterStemmer()
    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]

    return ' '.join(processed_tokens)

email = "Hello this is an example email to test the punctuation and stemmatization removal"
print("Original:", email)
print("Processed:", preprocess_text(email))

from sklearn.model_selection import train_test_split

X = df['text'].apply(preprocess_text)
Y = df['spam']

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 1)

"""Naive Bayes Classifier"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

vectorizer = CountVectorizer()
x_train_vec = vectorizer.fit_transform(x_train)
x_test_vec = vectorizer.transform(x_test)

nb = MultinomialNB()
nb.fit(x_train_vec, y_train)

prediction_NB = nb.predict(x_test_vec)
accuracy_NB = accuracy_score(y_test, prediction_NB)
print(f"Naive Bayes Classifier Accuracy: {accuracy_NB*100}")

from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(y_test, prediction_NB)

sb.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix - NB")
plt.show()

"""SVM"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

tfidf_vectorizer = TfidfVectorizer()
x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)
x_test_tfidf = tfidf_vectorizer.transform(x_test)

svm = SVC()
svm.fit(x_train_tfidf, y_train)

prediction_svm = svm.predict(x_test_tfidf)
accuracy_svm = accuracy_score(y_test, prediction_svm)
print(f"SVM Classifier Accuracy: {accuracy_svm*100}")

import pickle

with open('/Users/jedai/Desktop/Data Science Projects/Spam Classifier/tfidf_vectorizer.pkl','wb') as f:
  pickle.dump(tfidf_vectorizer, f)

with open('/Users/jedai/Desktop/Data Science Projects/Spam Classifier/model_spam.pkl','wb') as f:
    pickle.dump(svm,f)

conf_matrix = confusion_matrix(y_test, prediction_svm)

sb.heatmap(conf_matrix, annot=True, fmt="d", cmap="crest")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix - SVM")
plt.show()